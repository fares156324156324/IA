{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Jul/2023 08:56:25] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Jul/2023 08:56:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Jul/2023 08:56:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Jul/2023 08:56:34] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "import pickle\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "# Load the dataset\n",
    "df_list = pd.read_html('/home/fares/DatasetsOrange/offer.xls')\n",
    "df = df_list[0]\n",
    "df['Period'] = pd.to_datetime(df['Period'])  # Convert the index column to Timestamp objects\n",
    "df = df.set_index('Period')\n",
    "# Preprocess the dataset\n",
    "float_cols = df.columns\n",
    "df[float_cols] = df[float_cols].applymap(lambda x: str(x).replace(\",\", \".\"))\n",
    "df[float_cols] = df[float_cols].applymap(lambda x: str(x).replace(\" \", \"\"))\n",
    "df[float_cols] = df[float_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "df[float_cols] = df[float_cols].applymap(lambda x: x / (1024 * 1024 * 1024))\n",
    "\n",
    "# Model file path\n",
    "model_path = 'ARIMA.pkl'\n",
    "\n",
    "# Load the ARIMA model\n",
    "with open(model_path, 'rb') as file:\n",
    "    model_fit = pickle.load(file)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()  # Get JSON data from the request\n",
    "\n",
    "    column_name = data['column_name']\n",
    "    desired_days = data['desired_days']\n",
    "\n",
    "    # Generate a range of dates for prediction\n",
    "    start_date = df.index[-1] + pd.DateOffset(days=1)\n",
    "    end_date = start_date + pd.DateOffset(days=desired_days)\n",
    "\n",
    "    # Convert start_date and end_date to UTC timestamps\n",
    "    start_date_utc = start_date.tz_localize(None)\n",
    "    end_date_utc = end_date.tz_localize(None)\n",
    "\n",
    "    # Generate predictions using the loaded ARIMA model\n",
    "    predictions = model_fit.predict(start=start_date_utc, end=end_date_utc)\n",
    "\n",
    "    # Generate prediction dates in the local timezone\n",
    "    prediction_dates_local = pd.date_range(start=start_date, end=end_date, tz=df.index.tz)\n",
    "\n",
    "    # Create a list of dictionaries with dates and predictions\n",
    "    predictions_with_dates = [\n",
    "        {'date': date.strftime('%Y-%m-%d %H:%M:%S'), 'prediction': prediction}\n",
    "        for date, prediction in zip(prediction_dates_local, predictions)\n",
    "    ]\n",
    "\n",
    "    # Create response JSON\n",
    "    response = {\n",
    "        'predictions': predictions_with_dates\n",
    "    }\n",
    "\n",
    "    return jsonify(response)\n",
    "@app.route('/descriptive-curve', methods=['POST'])\n",
    "def descriptive_curve():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "\n",
    "        # Get input parameters from the request\n",
    "        column_name = data['column_name']  # Corrected this line\n",
    "        start_date = data['start_date']  # Add this line to get the start date\n",
    "        end_date = data['end_date']  # Add this line to get the end date\n",
    "\n",
    "        # Subset the dataset based on the specified date range\n",
    "        subset_df = df.loc[start_date:end_date, column_name]\n",
    "\n",
    "        # Get the values and dates of the descriptive curve\n",
    "        values = subset_df.values.tolist()\n",
    "        dates = subset_df.index.strftime('%Y-%m-%d').tolist()\n",
    "        data = [{'date': date, 'values': value} for date, value in zip(dates, values)]\n",
    "\n",
    "        # Create the response\n",
    "        response = {\n",
    "            'Data': data,\n",
    "        }\n",
    "\n",
    "        return jsonify(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        response = {\n",
    "            'error': error_message\n",
    "        }\n",
    "        return jsonify(response), 500\n",
    "@app.route('/all', methods=['POST'])\n",
    "def dataset_values():\n",
    "    try:\n",
    "        data = request.get_json()  # Get JSON data from the request\n",
    "\n",
    "        column_name = data['column_name']\n",
    "\n",
    "        # Get the values and dates for the specified column\n",
    "        values = df[column_name].values.tolist()\n",
    "        dates = df.index.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "        # Create a list of dictionaries with dates and values\n",
    "        data = [{'date': date, 'values': value} for date, value in zip(dates, values)]\n",
    "\n",
    "        # Create the response\n",
    "        response = {\n",
    "            'Data': data\n",
    "        }\n",
    "\n",
    "        return jsonify(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        response = {\n",
    "            'error': error_message\n",
    "        }\n",
    "        return jsonify(response), 500\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c426bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
